{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import TimeDistributed, Conv2D, MaxPooling2D, Flatten, LSTM, Dense\n",
    "\n",
    "img_width = 128\n",
    "img_height = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_frames(video_path, output_dir, num_frames=60):\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))  # get the total number of frames\n",
    "    start_frame = max(0, total_frames - num_frames)  # calculate the starting frame for the last n frames\n",
    "\n",
    "    success, image = vidcap.read()\n",
    "    count = 0\n",
    "    while success:\n",
    "        if count >= start_frame:  # only save frames from the last n frames\n",
    "            height, width, _ = image.shape  # get the dimensions of the frame\n",
    "            right_half = image[:, width//2:]  # select the right half of the frame\n",
    "            cv2.imwrite(output_dir + \"/frame%d.jpg\" % (count - start_frame), right_half)  # save frame as JPEG file\n",
    "        success, image = vidcap.read()\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"C:/Users/M/OneDrive - softromic/Documents/TreeHacks Fall Detection/falls\"\n",
    "dest = \"C:/Users/M/OneDrive - softromic/Documents/TreeHacks Fall Detection/video frames/vidframes - \"\n",
    "for i in range(30):\n",
    "    video_to_frames(os.path.join(directory, \"fall-\" + str(i+1) + \"-cam0.mp4\"), dest + str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_frames_from_folder(folder_path):\n",
    "    images = []\n",
    "    for filename in sorted(os.listdir(folder_path)):  # assuming all frames are named in ascending order\n",
    "        img = cv2.imread(os.path.join(folder_path, filename))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (img_width, img_height))\n",
    "            img = img / 255\n",
    "            images.append(img)\n",
    "    images = np.array(images)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_dir = \"C:/Users/M/OneDrive - softromic/Documents/TreeHacks Fall Detection/video frames\"\n",
    "all_videos_frames = []\n",
    "num_frames = 60\n",
    "\n",
    "for video_folder in os.listdir(frame_dir):\n",
    "    video_frames = load_frames_from_folder(os.path.join(frame_dir, video_folder))\n",
    "    video_frames = np.array(video_frames)\n",
    "    \n",
    "    # Ensure all videos have the same number of frames\n",
    "    if len(video_frames) < num_frames:\n",
    "        # If the video has fewer than num_frames frames, pad it with zeros\n",
    "        padding = np.zeros((num_frames - len(video_frames),) + video_frames.shape[1:])\n",
    "        video_frames = np.concatenate([video_frames, padding])\n",
    "    elif len(video_frames) > num_frames:\n",
    "        # If the video has more than num_frames frames, truncate it\n",
    "        video_frames = video_frames[:num_frames]\n",
    "    all_videos_frames.append(video_frames)\n",
    "\n",
    "all_videos_frames = np.array(all_videos_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_videos_labels = []\n",
    "for i in range(30):\n",
    "    all_videos_labels.append(1)\n",
    "for i in range(40):\n",
    "    all_videos_labels.append(0)\n",
    "\n",
    "all_videos_labels =  np.array(all_videos_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed (TimeDist  (None, 60, 96, 128, 32)   896       \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDi  (None, 60, 48, 64, 32)    0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDi  (None, 60, 48, 64, 64)    18496     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDi  (None, 60, 24, 32, 64)    0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDi  (None, 60, 24, 32, 128)   73856     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDi  (None, 60, 12, 16, 128)   0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_6 (TimeDi  (None, 60, 24576)         0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                6308096   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6405569 (24.44 MB)\n",
      "Trainable params: 6405569 (24.44 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "frame_shape = (img_height, img_width, 3)  # Height, Width, Channels\n",
    "\n",
    "# Define the number of frames in each sequence.\n",
    "sequence_length = 60\n",
    "\n",
    "model = Sequential([\n",
    "    # TimeDistributed wrapper allows applying the same layers individually to each time step.\n",
    "    TimeDistributed(Conv2D(32, (3, 3), activation='relu', padding='same'), input_shape=(sequence_length,) + frame_shape),\n",
    "    TimeDistributed(MaxPooling2D((2, 2))),\n",
    "    TimeDistributed(Conv2D(64, (3, 3), activation='relu', padding='same')),\n",
    "    TimeDistributed(MaxPooling2D((2, 2))),\n",
    "    TimeDistributed(Conv2D(128, (3, 3), activation='relu', padding='same')),\n",
    "    TimeDistributed(MaxPooling2D((2, 2))),\n",
    "    # Flatten the output of the conv layers so it can be fed into the LSTM layer\n",
    "    TimeDistributed(Flatten()),\n",
    "    # LSTM layer for analyzing the time series data\n",
    "    LSTM(64),\n",
    "    # Dense layers for classification\n",
    "    Dense(64, activation='relu'),\n",
    "    # Output layer for binary classification. Use 'sigmoid' activation for binary classification.\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1/1 [==============================] - 41s 41s/step - loss: 0.7034 - accuracy: 0.0000e+00 - val_loss: 0.2206 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.2339 - accuracy: 1.0000 - val_loss: 0.1105 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.1285 - accuracy: 1.0000 - val_loss: 0.0630 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 23s 23s/step - loss: 0.0797 - accuracy: 1.0000 - val_loss: 0.0320 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 27s 27s/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 23s 23s/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 29s 29s/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 19s 19s/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 34s 34s/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x254a9c35ed0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.arange(all_videos_frames.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "all_videos_frames = all_videos_frames[indices]\n",
    "all_videos_labels = all_videos_labels[indices]\n",
    "\n",
    "model.fit(all_videos_frames, all_videos_labels, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"C:/Users/M/OneDrive - softromic/Documents/TreeHacks Fall Detection/models/model.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
