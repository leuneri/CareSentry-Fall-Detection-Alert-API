{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import TimeDistributed, Conv2D, MaxPooling2D, Flatten, LSTM, Dense\n",
    "\n",
    "img_width = 128\n",
    "img_height = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number(num):\n",
    "    if num < 10:\n",
    "        return \"0\" + str(num)\n",
    "    return str(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_frames(video_path, output_dir, num_frames=60):\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))  # get the total number of frames\n",
    "    start_frame = max(0, total_frames - num_frames)  # calculate the starting frame for the last n frames\n",
    "\n",
    "    success, image = vidcap.read()\n",
    "    count = 0\n",
    "    while success:\n",
    "        if count >= start_frame:  # only save frames from the last n frames\n",
    "            height, width, _ = image.shape  # get the dimensions of the frame\n",
    "            right_half = image[:, width//2:]  # select the right half of the frame\n",
    "            cv2.imwrite(output_dir + \"/frame\" + get_number(count - start_frame) + \".jpg\", right_half)  # save frame as JPEG file\n",
    "        success, image = vidcap.read()\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"C:/Users/M/OneDrive - softromic/Documents/TreeHacks Fall Detection/falls\"\n",
    "dest = \"C:/Users/M/OneDrive - softromic/Documents/TreeHacks Fall Detection/video frames/vidframes - \"\n",
    "for i in range(30):\n",
    "    video_to_frames(directory + \"/fall-\" + str(i+1) + \"-cam0.mp4\", dest + str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"C:/Users/M/OneDrive - softromic/Documents/TreeHacks Fall Detection/nonfalls\"\n",
    "dest = \"C:/Users/M/OneDrive - softromic/Documents/TreeHacks Fall Detection/nonfall video frames/vidframes - \"\n",
    "for i in range(40):\n",
    "    video_to_frames(directory + \"/adl-\" + str(i+1) + \"-cam0.mp4\", dest + str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_frames_from_folder(folder_path):\n",
    "    images = []\n",
    "    for filename in sorted(os.listdir(folder_path)):  # assuming all frames are named in ascending order\n",
    "        img = cv2.imread(os.path.join(folder_path, filename))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (img_width, img_height))\n",
    "            img = img / 255\n",
    "            images.append(img)\n",
    "    images = np.array(images)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_frames(dir, num_frames):\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for video_folder in os.listdir(dir):\n",
    "        video_frames = load_frames_from_folder(os.path.join(dir, video_folder))\n",
    "        video_frames = np.array(video_frames)\n",
    "        \n",
    "        # Ensure all videos have the same number of frames\n",
    "        if len(video_frames) < num_frames:\n",
    "            # If the video has fewer than num_frames frames, pad it with zeros\n",
    "            padding = np.zeros((num_frames - len(video_frames),) + video_frames.shape[1:])\n",
    "            video_frames = np.concatenate([video_frames, padding])\n",
    "        elif len(video_frames) > num_frames:\n",
    "            # If the video has more than num_frames frames, truncate it\n",
    "            video_frames = video_frames[:num_frames]\n",
    "        frames.append(video_frames)\n",
    "    \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = 60\n",
    "\n",
    "fall_frame_dir = \"C:/Users/M/OneDrive - softromic/Documents/TreeHacks Fall Detection/video frames\"\n",
    "fall_videos_frames = compile_frames(fall_frame_dir, num_frames)\n",
    "\n",
    "nonfall_frame_dir = \"C:/Users/M/OneDrive - softromic/Documents/TreeHacks Fall Detection/nonfall video frames\"\n",
    "nonfall_videos_frames = compile_frames(nonfall_frame_dir, num_frames)\n",
    "\n",
    "all_videos_frames = fall_videos_frames\n",
    "for i in range(40):\n",
    "    all_videos_frames.append(nonfall_videos_frames[i])\n",
    "\n",
    "all_videos_frames = np.array(all_videos_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_videos_labels = []\n",
    "for i in range(30):\n",
    "    all_videos_labels.append(1)\n",
    "for i in range(40):\n",
    "    all_videos_labels.append(0)\n",
    "\n",
    "all_videos_labels =  np.array(all_videos_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed (TimeDist  (None, 60, 96, 128, 32)   896       \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDi  (None, 60, 48, 64, 32)    0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDi  (None, 60, 48, 64, 64)    18496     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDi  (None, 60, 24, 32, 64)    0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDi  (None, 60, 24, 32, 128)   73856     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDi  (None, 60, 12, 16, 128)   0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_6 (TimeDi  (None, 60, 24576)         0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                6308096   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6405569 (24.44 MB)\n",
      "Trainable params: 6405569 (24.44 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "frame_shape = (img_height, img_width, 3)  # Height, Width, Channels\n",
    "\n",
    "# Define the number of frames in each sequence.\n",
    "sequence_length = 60\n",
    "\n",
    "model = Sequential([\n",
    "    # TimeDistributed wrapper allows applying the same layers individually to each time step.\n",
    "    TimeDistributed(Conv2D(32, (3, 3), activation='relu', padding='same'), input_shape=(sequence_length,) + frame_shape),\n",
    "    TimeDistributed(MaxPooling2D((2, 2))),\n",
    "    TimeDistributed(Conv2D(64, (3, 3), activation='relu', padding='same')),\n",
    "    TimeDistributed(MaxPooling2D((2, 2))),\n",
    "    TimeDistributed(Conv2D(128, (3, 3), activation='relu', padding='same')),\n",
    "    TimeDistributed(MaxPooling2D((2, 2))),\n",
    "    # Flatten the output of the conv layers so it can be fed into the LSTM layer\n",
    "    TimeDistributed(Flatten()),\n",
    "    # LSTM layer for analyzing the time series data\n",
    "    LSTM(64),\n",
    "    # Dense layers for classification\n",
    "    Dense(64, activation='relu'),\n",
    "    # Output layer for binary classification. Use 'sigmoid' activation for binary classification.\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "2/2 [==============================] - 102s 42s/step - loss: 0.9720 - accuracy: 0.5179 - val_loss: 0.7044 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 76s 37s/step - loss: 0.7060 - accuracy: 0.6071 - val_loss: 0.7269 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 72s 29s/step - loss: 0.6882 - accuracy: 0.5893 - val_loss: 0.7382 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 73s 36s/step - loss: 0.6503 - accuracy: 0.5893 - val_loss: 0.6947 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 60s 28s/step - loss: 0.6094 - accuracy: 0.5893 - val_loss: 0.6479 - val_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 80s 35s/step - loss: 0.6687 - accuracy: 0.5893 - val_loss: 0.7108 - val_accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 84s 34s/step - loss: 0.5831 - accuracy: 0.5893 - val_loss: 0.5806 - val_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 68s 35s/step - loss: 0.4854 - accuracy: 0.6071 - val_loss: 0.4121 - val_accuracy: 0.9286\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 202s 34s/step - loss: 0.3462 - accuracy: 0.9464 - val_loss: 0.2720 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 74s 34s/step - loss: 0.2573 - accuracy: 1.0000 - val_loss: 0.1715 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1b632db3350>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.arange(all_videos_frames.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "all_videos_frames = all_videos_frames[indices]\n",
    "all_videos_labels = all_videos_labels[indices]\n",
    "\n",
    "model.fit(all_videos_frames, all_videos_labels, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"C:/Users/M/OneDrive - softromic/Documents/TreeHacks Fall Detection/models/model.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
